

# Staging Interaction

\*\***COLLABORATORS: wjr83 [GitHub Page](https://github.com/wjr83/Interactive-Lab-Hub)
**\*\*

In the original stage production of Peter Pan, Tinker Bell was represented by a darting light created by a small handheld mirror off-stage, reflecting a little circle of light from a powerful lamp. Tinkerbell communicates her presence through this light to the other characters. See more info [here](https://en.wikipedia.org/wiki/Tinker_Bell). 

There is no actor that plays Tinkerbell--her existence in the play comes from the interactions that the other characters have with her.

For lab this week, we draw on this and other inspirations from theatre to stage interactions with a device where the main mode of display/output for the interactive device you are designing is lighting. You will plot the interaction with a storyboard, and use your computer and a smartphone to experiment with what the interactions will look and feel like. 

_Make sure you read all the instructions and understand the whole of the laboratory activity before starting!_



## Prep

### To start the semester, you will need:
1. Read about Git [here](https://git-scm.com/book/en/v2/Getting-Started-What-is-Git%3F).
2. Set up your own Github "Lab Hub" repository to keep all you work in record by [following these instructions](https://github.com/FAR-Lab/Developing-and-Designing-Interactive-Devices/blob/2021Fall/readings/Submitting%20Labs.md).
3. Set up the README.md for your Hub repository (for instance, so that it has your name and points to your own Lab 1) and [learn how to](https://guides.github.com/features/mastering-markdown/) organize and post links to your submissions on your README.md so we can find them easily.


### For this lab, you will need:
1. Paper
2. Markers/ Pens
3. Scissors
4. Smart Phone -- The main required feature is that the phone needs to have a browser and display a webpage.
5. Computer -- We will use your computer to host a webpage which also features controls.
6. Found objects and materials -- You will have to costume your phone so that it looks like some other devices. These materials can include doll clothes, a paper lantern, a bottle, human clothes, a pillow case, etc. Be creative!

### Deliverables for this lab are: 
1. 7 Storyboards
1. 3 Sketches/photos of costumed devices
1. Any reflections you have on the process
1. Video sketch of 3 prototyped interactions
1. Submit the items above in the lab1 folder of your class [Github page], either as links or uploaded files. Each group member should post their own copy of the work to their own Lab Hub, even if some of the work is the same from each person in the group.

### The Report
This README.md page in your own repository should be edited to include the work you have done (the deliverables mentioned above). Following the format below, you can delete everything but the headers and the sections between the **stars**. Write the answers to the questions under the starred sentences. Include any material that explains what you did in this lab hub folder, and link it in your README.md for the lab.

## Lab Overview
For this assignment, you are going to:

A) [Plan](#part-a-plan) 

B) [Act out the interaction](#part-b-act-out-the-interaction) 

C) [Prototype the device](#part-c-prototype-the-device)

D) [Wizard the device](#part-d-wizard-the-device) 

E) [Costume the device](#part-e-costume-the-device)

F) [Record the interaction](#part-f-record)

Labs are due on Mondays. Make sure this page is linked to on your main class hub page.

## Part A. Plan 

To stage an interaction with your interactive device, think about:

_Setting:_ Where is this interaction happening? (e.g., a jungle, the kitchen) When is it happening?

This interaction is present in big cities where there is ample sound. Generally, sound waves are present everywhere and are constantly amplifying. Subconsciously and consciously, these sound waves affect our health. This problem is known as noise pollution. [Research](https://www.epa.gov/clean-air-act-overview/clean-air-act-title-iv-noise-pollution#:~:text=Noise%20pollution%20adversely%20affects%20the,sleep%20disruption%2C%20and%20lost%20productivity) indicates that noise pollution can result in hearing loss, exposure to loud noise can cause high blood pressure, heart disease, sleep disturbances, and stress. 


_Players:_ Who is involved in the interaction? Who else is there? If you reflect on the design of current day interactive devices like the Amazon Alexa, it’s clear they didn’t take into account people who had roommates, or the presence of children. Think through all the people who are in the setting.

People who want to know the level of harm the sounds around them may cause to them. People surrounding this informed individual could also be warned and then make an informed decision about whether or not they want to tune out the noises around them. 

_Activity:_ What is happening between the actors?

An individual goes about his/her day carrying or wearing his interactive device. Over the span of the day, the interactive device samples ambient noise every 5 seconds and informs the individual on the level of noise pillution through a color display. 

_Goals:_ What are the goals of each player? (e.g., jumping to a tree, opening the fridge). 

The purpose of this interaction is to mitigate the adverse effects of noise pollution on the human population. The following illustrations portray how the interactive device described below will alert the end user if exposed to unhealthy noise levels.

The interactive device can be anything *except* a computer, a tablet computer or a smart phone, but the main way it interacts needs to be using light.

\*\***Describe your setting, players, activity and goals here.**\*\*

Storyboards are a tool for visually exploring a users interaction with a device. They are a fast and cheap method to understand user flow, and iterate on a design before attempting to build on it. Take some time to read through this explanation of [storyboarding in UX design](https://www.smashingmagazine.com/2017/10/storyboarding-ux-design/). Sketch seven storyboards of the interactions you are planning. **It does not need to be perfect**, but must get across the behavior of the interactive device and the other characters in the scene. 

\*\***Include pictures of your storyboards here**\*\*

Present your ideas to the other people in your breakout room (or in small groups). You can just get feedback from one another or you can work together on the other parts of the lab.

**Legend:** Noise level in decibels (dB) color-coded.

<img width="550" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/a09dccee-5e2c-4027-89ea-6bc090b9ec4a">

|Noise level measured at a yoga class: 5 dB. Recorded sounds: breathing.|Noise level measured on a calm day at the park: 30 dB. Recorded sounds: rustling of leaves, gentle breeze, birds chirping at a distance.|
|:-:|:-:|
|<img width="300" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/bb4ca914-8a35-494b-bbbd-4d3aae2ede61">|<img width="300" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/a46a0447-a9c7-4bb9-b1a7-e48938c18825">|

|Noise level measured inside a car at 60mph, windows lowered: 60 dB|Noise level measured while using a lawn mower: 75 dB|
|:-:|:-:|
|<img width="300" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/16e226d3-b159-4d9b-9c88-16e255682a5f">|<img width="350" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/eca8b9e5-5916-4075-bc7b-376fd9a6861c">|

|Noise level measured while using an electric chainsaw: 90 dB|Noise level measured near sirens (police car, firefighters, ambulance): 120 dB|
|:-:|:-:|
|<img width="300" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/683a1e3c-34c6-4295-a009-a28c6d8b5ce9">|<img width="350" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/5c907645-1c50-4bcb-ae28-19316d9f9f13">|

|Noise level measured at a rock concert: 160 dB on stage (purple), 140 db first few rows (pink), 120 db at row 30 (red). | |
|:-:|:-:|
|<img width="600" alt="image" src="https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/b75cc68e-8f16-462d-92a7-f3c91dba3ac3">||



\*\***Summarize feedback you got here.**\*\*

Users asked us to consider people with different physical abilties. For example, how would we accomodate the app so that a color-blind user might be informed of the degree of the noise pollution (minimal to severe) without being confused by the colors?


## Part B. Act out the Interaction

Try physically acting out the interaction you planned. For now, you can just pretend the device is doing the things you’ve scripted for it. 

\*\***Are there things that seemed better on paper than acted out?**\*\*

Yes, we initially thought it would be more attentive to the changes in color while doing regular activities throughout the day. However, we recieve so many notifications throughout the day, it is hard to go through everything and remember to do everything. Additionally, some users prefer to minimize screentime as much as possible. Therefore, we think it would be an additional effort to constantly glance at the interactive device to verify whether the noise pollution we are exposed to exceeds the recommended upper limit. We have considered incorporating audio notifications but that defeats the purpose since calling the user's attention if the noise levels are close to reaching those that could cause further hearing damage. The device should make greater and greater efforts to alert the user if the noise level continues to intensify past the safe limits.

\*\***Are there new ideas that occur to you or your collaborators that come up from the acting?**\*\*

We have considered notifying the user of an unhealthy increase in noise level through vibrations? Furthermore, we want to explorw how 
an interactive device could also help mitigate the adverse consequences of noise pollution by dampening the noise pollution if the decibels measured exceed a certain threshold. For example, the Centers for Disease Control advises that prolonged exposure to noise above 70 dB starts to deteriorate one's hearing sensitivity. Additionally, noises above 120 dB result in immediate harm to the ears. Therefore, to reduce or eliminate harmful noise levels, the interactive device could generate anti-noise sounds to cancel or reduce the perceived noises of the environment.

Another teammate drew a storyboard of an air pollution sensor that could be designed in a similar way as the noise pollution sensor described. This could be incorpoted in future iterations where we add more features. Refer to the rough storyboard below of the air pollution interaction. **NOTE:** For the purposes of this lab, we will focus on the noise pollution interactive device.
![new doc 2023-08-27 23 56 08_1](https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/af997e92-0ff9-4edf-a384-0fb36c24d62a)



## Part C. Prototype the device

You will be using your smartphone as a stand-in for the device you are prototyping. You will use the browser of your smart phone to act as a “light” and use a remote control interface to remotely change the light on that device. 

Code for the "Tinkerbelle" tool, and instructions for setting up the server and your phone are [here](https://github.com/FAR-Lab/tinkerbelle).

We invented this tool for this lab! 

If you run into technical issues with this tool, you can also use a light switch, dimmer, etc. that you can can manually or remotely control.

\*\***Give us feedback on Tinkerbelle.**\*\*

Tinkerbelle was a realistically easy project to set up. However, I encountered some port and window incompatibility. The TA then instructed me to checkout the requirements.txt file from a previous commit 46fb9d2515af98816637e98d96228f7a9faba470 . 

## Part D. Wizard the device
Take a little time to set up the wizarding set-up that allows for someone to remotely control the device while someone acts with it. Hint: You can use Zoom to record videos, and you can pin someone’s video feed if that is the scene which you want to record. 

\*\***Include your first attempts at recording the set-up video here.**\*\*

Now, hange the goal within the same setting, and update the interaction with the paper prototype. 

\*\***Show the follow-up work here.**\*\*


## Part E. Costume the device

Only now should you start worrying about what the device should look like. Develop three costumes so that you can use your phone as this device.

Think about the setting of the device: is the environment a place where the device could overheat? Is water a danger? Does it need to have bright colors in an emergency setting?

Costume #1 & #2:
![image](https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/2d3b5775-eb0f-480a-8dc2-8931a5e51ebd)

Costume #3: A student ID or work ID will flash a decibel color according to the ambient noise loudness measured.
![image_6487327](https://github.com/wjr83/Interactive-Lab-Hub/assets/143034234/0d0a3cc9-68a5-4f74-9540-009e941d8295)

\*\***What concerns or opportunities are influencing the way you've designed the device to look?**\*\*
Hospital systems have programs that require doctors exposed to radiation to wear dosimeters. These dosimeters are devices that measure and record the amount of radiation a person receives over time. They are mandated by state and federal regulations, particularly when someone is likely to receive over 10% of the maximum permissible dose. In a hospital setting, these dosimeters often resemble badges and go unnoticed by most people who are unfamiliar with the technology.

The third costume shown above was designed with a focus on dosimeters used by interventional radiologists. Additionally, the goal was to integrate a noise sensor into everyday objects so that users would naturally carry this interactive noise sensor without needing to remember it. Everyday items like a watch (as seen in costume #1), keys (inspiring the keychain of costume #2), and a student ID or work badge (featured in costume #3) were considered for this purpose.

## Part F. Record

\*\***Take a video of your prototyped interaction.**\*\*

\*\***Please indicate anyone you collaborated with on this Lab.**\*\*
Be generous in acknowledging their contributions! And also recognizing any other influences (e.g. from YouTube, Github, Twitter) that informed your design. 



# Staging Interaction, Part 2 

This describes the second week's work for this lab activity.


## Prep (to be done before Lab on Wednesday)

You will be assigned three partners from another group. Go to their github pages, view their videos, and provide them with reactions, suggestions & feedback: explain to them what you saw happening in their video. Guess the scene and the goals of the character. Ask them about anything that wasn’t clear. 

\*\***Summarize feedback from your partners here.**\*\*

## Make it your own

Do last week’s assignment again, but this time: 
1) It doesn’t have to (just) use light, 
2) You can use any modality (e.g., vibration, sound) to prototype the behaviors! Again, be creative! Feel free to fork and modify the tinkerbell code! 
3) We will be grading with an emphasis on creativity. 

\*\***Document everything here. (Particularly, we would like to see the storyboard and video, although photos of the prototype are also great.)**\*\*
